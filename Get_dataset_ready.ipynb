{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import glob\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "# from tifffile import imsave\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 11:38:23.427335: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-28 11:38:23.648809: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Od4WYwjAsLd4YRCh-NGWezSFk8VL6Pju\n",
      "From (redirected): https://drive.google.com/uc?id=1Od4WYwjAsLd4YRCh-NGWezSFk8VL6Pju&confirm=t&uuid=9dd3a1e6-e862-49e4-b747-0e13f7c36784\n",
      "To: /home/.ipython/brats_2021.zip\n",
      "100%|██████████| 13.2G/13.2G [05:32<00:00, 39.7MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'brats_2021.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "# Replace 'FILE_ID' with your actual Google Drive file ID\n",
    "file_id = '1Od4WYwjAsLd4YRCh-NGWezSFk8VL6Pju'\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "gdown.download(url, output='brats_2021.zip', quiet=False, fuzzy=True, use_cookies=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1-iopapbMbkWShYpJaOUmLLIhf8JkUHqu\n",
      "From (redirected): https://drive.google.com/uc?id=1-iopapbMbkWShYpJaOUmLLIhf8JkUHqu&confirm=t&uuid=d66651b2-54fc-43d0-bc4f-9c28e04f5afe\n",
      "To: /home/.ipython/brats_2020.zip\n",
      "100%|██████████| 4.47G/4.47G [01:58<00:00, 37.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'brats_2020.zip'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "# Replace 'FILE_ID' with your actual Google Drive file ID\n",
    "file_id = '1-iopapbMbkWShYpJaOUmLLIhf8JkUHqu'\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "gdown.download(url, output='brats_2020.zip', quiet=False, fuzzy=True, use_cookies=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping complete!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Path to your ZIP file\n",
    "zip_file_path = \"brats_2021.zip\"\n",
    "\n",
    "# Destination folder where files will be extracted\n",
    "extract_to_folder = \"2021_dataset\"\n",
    "\n",
    "# Open and extract the ZIP file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_folder)\n",
    "\n",
    "print(\"Unzipping complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete!\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "# Path to your TAR file\n",
    "tar_file_path = \"BraTS2021_Training_Data.tar\"\n",
    "\n",
    "# Destination folder where files will be extracted\n",
    "extract_to_folder = \"2021_dataset\"\n",
    "\n",
    "# Open and extract the TAR file\n",
    "with tarfile.open(tar_file_path, 'r') as tar_ref:\n",
    "    tar_ref.extractall(extract_to_folder)\n",
    "\n",
    "print(\"Extraction complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unzip the files in the folders \n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "# Set the root directory where 'folder1' exists\n",
    "root_directory = \"2021_dataset\"\n",
    "\n",
    "# Walk through all subdirectories\n",
    "for subdir, _, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".gz\"):\n",
    "            gz_path = os.path.join(subdir, file)  # Full path to .gz file\n",
    "            extracted_file_path = os.path.join(subdir, os.path.splitext(file)[0])  # Remove .gz extension\n",
    "\n",
    "            try:\n",
    "                # Extract the .gz file\n",
    "                with gzip.open(gz_path, 'rb') as f_in:\n",
    "                    with open(extracted_file_path, 'wb') as f_out:\n",
    "                        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "                # print(f\"Extracted: {gz_path}\")\n",
    "\n",
    "                # Delete the original .gz file\n",
    "                os.remove(gz_path)\n",
    "                # print(f\"Deleted: {gz_path}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {gz_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if any .gz file is remaining, use this\n",
    "import os \n",
    "\n",
    "root_directory = \"2021_dataset\"\n",
    "\n",
    "for subdir, _, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".gz\"):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted compressed file: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping complete!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Path to your ZIP file\n",
    "zip_file_path = \"brats_2020.zip\"\n",
    "\n",
    "# Destination folder where files will be extracted\n",
    "extract_to_folder = \"2020_dataset\"\n",
    "\n",
    "# Open and extract the ZIP file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_to_folder)\n",
    "\n",
    "print(\"Unzipping complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved: BraTS20_Training_001\n",
      "Moved: BraTS20_Training_002\n",
      "Moved: BraTS20_Training_003\n",
      "Moved: BraTS20_Training_004\n",
      "Moved: BraTS20_Training_005\n",
      "Moved: BraTS20_Training_006\n",
      "Moved: BraTS20_Training_007\n",
      "Moved: BraTS20_Training_008\n",
      "Moved: BraTS20_Training_009\n",
      "Moved: BraTS20_Training_010\n",
      "Moved: BraTS20_Training_011\n",
      "Moved: BraTS20_Training_012\n",
      "Moved: BraTS20_Training_013\n",
      "Moved: BraTS20_Training_014\n",
      "Moved: BraTS20_Training_015\n",
      "Moved: BraTS20_Training_016\n",
      "Moved: BraTS20_Training_017\n",
      "Moved: BraTS20_Training_018\n",
      "Moved: BraTS20_Training_019\n",
      "Moved: BraTS20_Training_020\n",
      "Moved: BraTS20_Training_021\n",
      "Moved: BraTS20_Training_022\n",
      "Moved: BraTS20_Training_023\n",
      "Moved: BraTS20_Training_024\n",
      "Moved: BraTS20_Training_025\n",
      "Moved: BraTS20_Training_026\n",
      "Moved: BraTS20_Training_027\n",
      "Moved: BraTS20_Training_028\n",
      "Moved: BraTS20_Training_029\n",
      "Moved: BraTS20_Training_030\n",
      "Moved: BraTS20_Training_031\n",
      "Moved: BraTS20_Training_032\n",
      "Moved: BraTS20_Training_033\n",
      "Moved: BraTS20_Training_034\n",
      "Moved: BraTS20_Training_035\n",
      "Moved: BraTS20_Training_036\n",
      "Moved: BraTS20_Training_037\n",
      "Moved: BraTS20_Training_038\n",
      "Moved: BraTS20_Training_039\n",
      "Moved: BraTS20_Training_040\n",
      "Moved: BraTS20_Training_041\n",
      "Moved: BraTS20_Training_042\n",
      "Moved: BraTS20_Training_043\n",
      "Moved: BraTS20_Training_044\n",
      "Moved: BraTS20_Training_045\n",
      "Moved: BraTS20_Training_046\n",
      "Moved: BraTS20_Training_047\n",
      "Moved: BraTS20_Training_048\n",
      "Moved: BraTS20_Training_049\n",
      "Moved: BraTS20_Training_050\n",
      "Moved: BraTS20_Training_051\n",
      "Moved: BraTS20_Training_052\n",
      "Moved: BraTS20_Training_053\n",
      "Moved: BraTS20_Training_054\n",
      "Moved: BraTS20_Training_055\n",
      "Moved: BraTS20_Training_056\n",
      "Moved: BraTS20_Training_057\n",
      "Moved: BraTS20_Training_058\n",
      "Moved: BraTS20_Training_059\n",
      "Moved: BraTS20_Training_060\n",
      "Moved: BraTS20_Training_061\n",
      "Moved: BraTS20_Training_062\n",
      "Moved: BraTS20_Training_063\n",
      "Moved: BraTS20_Training_064\n",
      "Moved: BraTS20_Training_065\n",
      "Moved: BraTS20_Training_066\n",
      "Moved: BraTS20_Training_067\n",
      "Moved: BraTS20_Training_068\n",
      "Moved: BraTS20_Training_069\n",
      "Moved: BraTS20_Training_070\n",
      "Moved: BraTS20_Training_071\n",
      "Moved: BraTS20_Training_072\n",
      "Moved: BraTS20_Training_073\n",
      "Moved: BraTS20_Training_074\n",
      "Moved: BraTS20_Training_075\n",
      "Moved: BraTS20_Training_076\n",
      "Moved: BraTS20_Training_077\n",
      "Moved: BraTS20_Training_078\n",
      "Moved: BraTS20_Training_079\n",
      "Moved: BraTS20_Training_080\n",
      "Moved: BraTS20_Training_081\n",
      "Moved: BraTS20_Training_082\n",
      "Moved: BraTS20_Training_083\n",
      "Moved: BraTS20_Training_084\n",
      "Moved: BraTS20_Training_085\n",
      "Moved: BraTS20_Training_086\n",
      "Moved: BraTS20_Training_087\n",
      "Moved: BraTS20_Training_088\n",
      "Moved: BraTS20_Training_089\n",
      "Moved: BraTS20_Training_090\n",
      "Moved: BraTS20_Training_091\n",
      "Moved: BraTS20_Training_092\n",
      "Moved: BraTS20_Training_093\n",
      "Moved: BraTS20_Training_094\n",
      "Moved: BraTS20_Training_095\n",
      "Moved: BraTS20_Training_096\n",
      "Moved: BraTS20_Training_097\n",
      "Moved: BraTS20_Training_098\n",
      "Moved: BraTS20_Training_099\n",
      "Moved: BraTS20_Training_100\n",
      "Moved: BraTS20_Training_101\n",
      "Moved: BraTS20_Training_102\n",
      "Moved: BraTS20_Training_103\n",
      "Moved: BraTS20_Training_104\n",
      "Moved: BraTS20_Training_105\n",
      "Moved: BraTS20_Training_106\n",
      "Moved: BraTS20_Training_107\n",
      "Moved: BraTS20_Training_108\n",
      "Moved: BraTS20_Training_109\n",
      "Moved: BraTS20_Training_110\n",
      "Moved: BraTS20_Training_111\n",
      "Moved: BraTS20_Training_112\n",
      "Moved: BraTS20_Training_113\n",
      "Moved: BraTS20_Training_114\n",
      "Moved: BraTS20_Training_115\n",
      "Moved: BraTS20_Training_116\n",
      "Moved: BraTS20_Training_117\n",
      "Moved: BraTS20_Training_118\n",
      "Moved: BraTS20_Training_119\n",
      "Moved: BraTS20_Training_120\n",
      "Moved: BraTS20_Training_121\n",
      "Moved: BraTS20_Training_122\n",
      "Moved: BraTS20_Training_123\n",
      "Moved: BraTS20_Training_124\n",
      "Moved: BraTS20_Training_125\n",
      "Moved: BraTS20_Training_126\n",
      "Moved: BraTS20_Training_127\n",
      "Moved: BraTS20_Training_128\n",
      "Moved: BraTS20_Training_129\n",
      "Moved: BraTS20_Training_130\n",
      "Moved: BraTS20_Training_131\n",
      "Moved: BraTS20_Training_132\n",
      "Moved: BraTS20_Training_133\n",
      "Moved: BraTS20_Training_134\n",
      "Moved: BraTS20_Training_135\n",
      "Moved: BraTS20_Training_136\n",
      "Moved: BraTS20_Training_137\n",
      "Moved: BraTS20_Training_138\n",
      "Moved: BraTS20_Training_139\n",
      "Moved: BraTS20_Training_140\n",
      "Moved: BraTS20_Training_141\n",
      "Moved: BraTS20_Training_142\n",
      "Moved: BraTS20_Training_143\n",
      "Moved: BraTS20_Training_144\n",
      "Moved: BraTS20_Training_145\n",
      "Moved: BraTS20_Training_146\n",
      "Moved: BraTS20_Training_147\n",
      "Moved: BraTS20_Training_148\n",
      "Moved: BraTS20_Training_149\n",
      "Moved: BraTS20_Training_150\n",
      "Moved: BraTS20_Training_151\n",
      "Moved: BraTS20_Training_152\n",
      "Moved: BraTS20_Training_153\n",
      "Moved: BraTS20_Training_154\n",
      "Moved: BraTS20_Training_155\n",
      "Moved: BraTS20_Training_156\n",
      "Moved: BraTS20_Training_157\n",
      "Moved: BraTS20_Training_158\n",
      "Moved: BraTS20_Training_159\n",
      "Moved: BraTS20_Training_160\n",
      "Moved: BraTS20_Training_161\n",
      "Moved: BraTS20_Training_162\n",
      "Moved: BraTS20_Training_163\n",
      "Moved: BraTS20_Training_164\n",
      "Moved: BraTS20_Training_165\n",
      "Moved: BraTS20_Training_166\n",
      "Moved: BraTS20_Training_167\n",
      "Moved: BraTS20_Training_168\n",
      "Moved: BraTS20_Training_169\n",
      "Moved: BraTS20_Training_170\n",
      "Moved: BraTS20_Training_171\n",
      "Moved: BraTS20_Training_172\n",
      "Moved: BraTS20_Training_173\n",
      "Moved: BraTS20_Training_174\n",
      "Moved: BraTS20_Training_175\n",
      "Moved: BraTS20_Training_176\n",
      "Moved: BraTS20_Training_177\n",
      "Moved: BraTS20_Training_178\n",
      "Moved: BraTS20_Training_179\n",
      "Moved: BraTS20_Training_180\n",
      "Moved: BraTS20_Training_181\n",
      "Moved: BraTS20_Training_182\n",
      "Moved: BraTS20_Training_183\n",
      "Moved: BraTS20_Training_184\n",
      "Moved: BraTS20_Training_185\n",
      "Moved: BraTS20_Training_186\n",
      "Moved: BraTS20_Training_187\n",
      "Moved: BraTS20_Training_188\n",
      "Moved: BraTS20_Training_189\n",
      "Moved: BraTS20_Training_190\n",
      "Moved: BraTS20_Training_191\n",
      "Moved: BraTS20_Training_192\n",
      "Moved: BraTS20_Training_193\n",
      "Moved: BraTS20_Training_194\n",
      "Moved: BraTS20_Training_195\n",
      "Moved: BraTS20_Training_196\n",
      "Moved: BraTS20_Training_197\n",
      "Moved: BraTS20_Training_198\n",
      "Moved: BraTS20_Training_199\n",
      "Moved: BraTS20_Training_200\n",
      "✅ Done! Moved 100 subfolders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths (Update these!)\n",
    "folder1 = \"2020_dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\"  # Source folder\n",
    "destination_folder = \"2021_dataset\"  # Destination folder\n",
    "\n",
    "# Get all subfolders in folder1 (sorted for consistency)\n",
    "subfolders = [f for f in sorted(os.listdir(folder1)) if os.path.isdir(os.path.join(folder1, f))]\n",
    "\n",
    "# Move the first 100 subfolders\n",
    "for subfolder in subfolders[:200]:  \n",
    "    src_path = os.path.join(folder1, subfolder)\n",
    "    dest_path = os.path.join(destination_folder, subfolder)\n",
    "\n",
    "    shutil.move(src_path, dest_path)  # Moves the subfolder\n",
    "    print(f\"Moved: {subfolder}\")\n",
    "\n",
    "print(\"✅ Done! Moved 100 subfolders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # images lists harley\n",
    "#t1_list = sorted(glob.glob('BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*t1.nii'))\n",
    "\n",
    "import glob \n",
    "import os\n",
    "import shutil\n",
    "\n",
    "folder1_path = \"2021_dataset\"\n",
    "\n",
    "t2_list = sorted(glob.glob('2021_dataset/*/*t2.nii'))\n",
    "t1ce_list = sorted(glob.glob('2021_dataset/*/*t1ce.nii'))\n",
    "flair_list = sorted(glob.glob('2021_dataset/*/*flair.nii'))\n",
    "mask_list = sorted(glob.glob('2021_dataset/*/*seg.nii'))\n",
    "\n",
    "#Each volume generates 18 64x64x64x4 sub-volumes. \n",
    "#Total 369 volumes = 6642 sub volumes\n",
    "\n",
    "for img in range(len(t2_list)):   #Using t1_list as all lists are of same size\n",
    "    # print(\"Now preparing image and masks number: \", img)\n",
    "      \n",
    "    temp_image_t2=nib.load(t2_list[img]).get_fdata()\n",
    "    temp_image_t2=scaler.fit_transform(temp_image_t2.reshape(-1, temp_image_t2.shape[-1])).reshape(temp_image_t2.shape)\n",
    "   \n",
    "    temp_image_t1ce=nib.load(t1ce_list[img]).get_fdata()\n",
    "    temp_image_t1ce=scaler.fit_transform(temp_image_t1ce.reshape(-1, temp_image_t1ce.shape[-1])).reshape(temp_image_t1ce.shape)\n",
    "   \n",
    "    temp_image_flair=nib.load(flair_list[img]).get_fdata()\n",
    "    temp_image_flair=scaler.fit_transform(temp_image_flair.reshape(-1, temp_image_flair.shape[-1])).reshape(temp_image_flair.shape)\n",
    "        \n",
    "    temp_mask=nib.load(mask_list[img]).get_fdata()\n",
    "    temp_mask=temp_mask.astype(np.uint8)\n",
    "    temp_mask[temp_mask==4] = 3  #Reassign mask values 4 to 3\n",
    "    #print(np.unique(temp_mask))\n",
    "    \n",
    "    \n",
    "    combine_3Images_training = np.stack([temp_image_flair, temp_image_t1ce, temp_image_t2], axis=3)\n",
    "    \n",
    "    #Crop to a size to be divisible by 64 so we can later extract 64x64x64 patches. \n",
    "    #cropping x, y, and z\n",
    "    combine_3Images_training=combine_3Images_training[56:184, 56:184, 13:141]\n",
    "    temp_mask = temp_mask[56:184, 56:184, 13:141]\n",
    "    \n",
    "    val, counts = np.unique(temp_mask, return_counts=True)\n",
    "    \n",
    "    if (1 - (counts[0]/counts.sum())) > 0.01:  #At least 1% useful volume with labels that are not 0\n",
    "        # print(\"Save Me\")\n",
    "        temp_mask= to_categorical(temp_mask, num_classes=4)\n",
    "        np.save('2020_2021_Dataset/images/image_'+str(img)+'.npy', combine_3Images_training)\n",
    "        np.save('2020_2021_Dataset/masks/mask_'+str(img)+'.npy', temp_mask)\n",
    "    else:\n",
    "        pass \n",
    "        # print(\"I am useless\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 1335\n",
      "Number of masks: 1335\n"
     ]
    }
   ],
   "source": [
    "#Print No. of images/masks in trainning dataset \n",
    "\n",
    "import os\n",
    "\n",
    "# Replace this with your main folder path\n",
    "main_folder = '2020_2021_Dataset/images'\n",
    "masks_folder = '2020_2021_Dataset/masks'\n",
    "\n",
    "images = [f for f in os.listdir(main_folder) if os.path.isfile(os.path.join(main_folder, f))]\n",
    "masks = [f for f in os.listdir(masks_folder) if os.path.isfile(os.path.join(masks_folder, f))]\n",
    "\n",
    "# Print the count\n",
    "print(\"Number of images:\", len(images))\n",
    "print(\"Number of masks:\", len(masks)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation dataset work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/.ipython/Get_dataset_ready.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://8c14722964090.notebooks.jarvislabs.net/home/.ipython/Get_dataset_ready.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m temp_image_flair\u001b[39m=\u001b[39mnib\u001b[39m.\u001b[39mload(flair_list[img])\u001b[39m.\u001b[39mget_fdata()\n\u001b[1;32m     <a href='vscode-notebook-cell://8c14722964090.notebooks.jarvislabs.net/home/.ipython/Get_dataset_ready.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m temp_image_flair\u001b[39m=\u001b[39mscaler\u001b[39m.\u001b[39mfit_transform(temp_image_flair\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, temp_image_flair\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\u001b[39m.\u001b[39mreshape(temp_image_flair\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell://8c14722964090.notebooks.jarvislabs.net/home/.ipython/Get_dataset_ready.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m temp_mask\u001b[39m=\u001b[39mnib\u001b[39m.\u001b[39mload(mask_list[img])\u001b[39m.\u001b[39mget_fdata()\n\u001b[1;32m     <a href='vscode-notebook-cell://8c14722964090.notebooks.jarvislabs.net/home/.ipython/Get_dataset_ready.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m temp_mask\u001b[39m=\u001b[39mtemp_mask\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8)\n\u001b[1;32m     <a href='vscode-notebook-cell://8c14722964090.notebooks.jarvislabs.net/home/.ipython/Get_dataset_ready.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m temp_mask[temp_mask\u001b[39m==\u001b[39m\u001b[39m4\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m  \u001b[39m#Reassign mask values 4 to 3\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# # # images lists harley\n",
    "#t1_list = sorted(glob.glob('BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*t1.nii'))\n",
    "\n",
    "import glob \n",
    "import os\n",
    "import shutil\n",
    "import nibabel as nib \n",
    "\n",
    "folder1_path = \"moved_folder\"\n",
    "\n",
    "t2_list = sorted(glob.glob('2020_dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*t2.nii'))\n",
    "t1ce_list = sorted(glob.glob('2020_dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*t1ce.nii'))\n",
    "flair_list = sorted(glob.glob('2020_dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*flair.nii'))\n",
    "mask_list = sorted(glob.glob('2020_dataset/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/*/*seg.nii'))\n",
    "\n",
    "#Each volume generates 18 64x64x64x4 sub-volumes. \n",
    "#Total 369 volumes = 6642 sub volumes\n",
    "\n",
    "for img in range(len(t2_list)):   #Using t1_list as all lists are of same size\n",
    "    # print(\"Now preparing image and masks number: \", img)\n",
    "      \n",
    "    temp_image_t2=nib.load(t2_list[img]).get_fdata()\n",
    "    temp_image_t2=scaler.fit_transform(temp_image_t2.reshape(-1, temp_image_t2.shape[-1])).reshape(temp_image_t2.shape)\n",
    "   \n",
    "    temp_image_t1ce=nib.load(t1ce_list[img]).get_fdata()\n",
    "    temp_image_t1ce=scaler.fit_transform(temp_image_t1ce.reshape(-1, temp_image_t1ce.shape[-1])).reshape(temp_image_t1ce.shape)\n",
    "   \n",
    "    temp_image_flair=nib.load(flair_list[img]).get_fdata()\n",
    "    temp_image_flair=scaler.fit_transform(temp_image_flair.reshape(-1, temp_image_flair.shape[-1])).reshape(temp_image_flair.shape)\n",
    "        \n",
    "    temp_mask=nib.load(mask_list[img]).get_fdata()\n",
    "    temp_mask=temp_mask.astype(np.uint8)\n",
    "    temp_mask[temp_mask==4] = 3  #Reassign mask values 4 to 3\n",
    "    #print(np.unique(temp_mask))\n",
    "    \n",
    "    \n",
    "    combine_3Images_validation = np.stack([temp_image_flair, temp_image_t1ce, temp_image_t2], axis=3)\n",
    "    \n",
    "    #Crop to a size to be divisible by 64 so we can later extract 64x64x64 patches. \n",
    "    #cropping x, y, and z\n",
    "    combine_3Images_validation=combine_3Images_validation[56:184, 56:184, 13:141]\n",
    "    temp_mask = temp_mask[56:184, 56:184, 13:141]\n",
    "    \n",
    "    val, counts = np.unique(temp_mask, return_counts=True)\n",
    "    \n",
    "    if (1 - (counts[0]/counts.sum())) > 0.01:  #At least 1% useful volume with labels that are not 0\n",
    "        # print(\"Save Me\")\n",
    "        temp_mask= to_categorical(temp_mask, num_classes=4)\n",
    "        np.save('2020_2021_Validation/images/image_'+str(img)+'.npy', combine_3Images_validation)\n",
    "        np.save('2020_2021_Validation/masks/mask_'+str(img)+'.npy', temp_mask)\n",
    "    else:\n",
    "        pass \n",
    "        # print(\"I am useless\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation images: 159\n",
      "Number of validation masks: 159\n"
     ]
    }
   ],
   "source": [
    "#Print No. of images/masks in Validation dataset \n",
    "\n",
    "import os\n",
    "\n",
    "# Replace this with your main folder path\n",
    "main_folder = '2020_2021_Validation/images'\n",
    "masks_folder = '2020_2021_Validation/masks'\n",
    "\n",
    "images = [f for f in os.listdir(main_folder) if os.path.isfile(os.path.join(main_folder, f))]\n",
    "masks = [f for f in os.listdir(masks_folder) if os.path.isfile(os.path.join(masks_folder, f))]\n",
    "\n",
    "# Print the count\n",
    "print(\"Number of validation images:\", len(images))\n",
    "print(\"Number of validation masks:\", len(masks)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
